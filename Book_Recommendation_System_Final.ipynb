{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-2.4.6-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate spark context\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf=pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc=pyspark.SparkContext(conf=conf)\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import udf,col,when\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show all predicted image\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark session\n",
    "#create s spark context\n",
    "\n",
    "spark=ps.sql.SparkSession.builder\\\n",
    "          .master(\"local\")\\\n",
    "          .appName(\"Youtube demo book\")\\\n",
    "          .getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sqlContext=SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- best_book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: double (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: double (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: double (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df=sqlContext.read.csv('D:/Big data project/books.csv',header=True,inferSchema=True)\n",
    "books_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df=sqlContext.read.csv('D:/Big data project/ratings.csv',header=True,inferSchema=True)\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df,validation_df=ratings_df.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=10\n",
    "regularization_parameter=0.1 #lambda\n",
    "rank=4 #rank\n",
    "errors=[]\n",
    "err=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error Value=0.8990440950634098\n"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=iterations,regParam=regularization_parameter,rank=5,userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\")\n",
    "model=als.fit(training_df)\n",
    "predictions=model.transform(validation_df)\n",
    "new_predictions=predictions.filter(col('prediction')!=np.nan)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(new_predictions)\n",
    "print(\"Root Mean Square Error Value=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error Value=0.9054410323777868\n"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=iterations,regParam=regularization_parameter,rank=6,userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\")\n",
    "model=als.fit(training_df)\n",
    "predictions=model.transform(validation_df)\n",
    "new_predictions=predictions.filter(col('prediction')!=np.nan)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(new_predictions)\n",
    "print(\"Root Mean Square Error Value=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error Value=0.9054292722328021\n"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=iterations,regParam=regularization_parameter,rank=7,userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\")\n",
    "model=als.fit(training_df)\n",
    "predictions=model.transform(validation_df)\n",
    "new_predictions=predictions.filter(col('prediction')!=np.nan)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(new_predictions)\n",
    "print(\"Root Mean Square Error Value=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error Value=0.8883537933417726\n"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=iterations,regParam=regularization_parameter,rank=3,userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\")\n",
    "model=als.fit(training_df)\n",
    "predictions=model.transform(validation_df)\n",
    "new_predictions=predictions.filter(col('prediction')!=np.nan)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(new_predictions)\n",
    "print(\"Root Mean Square Error Value=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-2.4.6-bin-hadoop2.7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate spark context\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession         #main entry point for dataframe and SQL functionality\n",
    "conf=pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc=pyspark.SparkContext(conf=conf)\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext  #It is the main entry point for spark functionalities.it is used to data frame.\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # allows to mesaure the performance of ALS model\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder #to cross validate and fine tune hyperparameters of our model\n",
    "from pyspark.ml import Pipeline #ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.\n",
    "from pyspark.sql import Row     # A row of data in a data frame\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import udf,col,when #user defined functions \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show all predicted image\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark session\n",
    "#create s spark context\n",
    "\n",
    "spark=ps.sql.SparkSession.builder\\\n",
    "          .master(\"local\")\\\n",
    "          .appName(\"Book Recommendation System\")\\       #Sets a name for the application, which will be shown in the Spark web UI.\n",
    "          .getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- best_book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: double (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: double (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: double (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df=sqlContext.read.csv('D:/Big data project/books.csv',header=True,inferSchema=True)\n",
    "books_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df=sqlContext.read.csv('D:/Big data project/ratings.csv',header=True,inferSchema=True)\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df,validation_df=ratings_df.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=10\n",
    "regularization_parameter=0.1 #lambda ,to prevent ALS from overfitting the data\n",
    "rank=4 #rank\n",
    "errors=[]\n",
    "err=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error Value=0.8936945536026696\n"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=iterations,regParam=regularization_parameter,rank=3,userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\")\n",
    "model=als.fit(training_df)\n",
    "predictions=model.transform(validation_df)\n",
    "new_predictions=predictions.filter(col('prediction')!=np.nan)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\") #evaluator set to our rmse tell spark which column contains our labels and then what we wanted to name the output prediction.\n",
    "rmse=evaluator.evaluate(new_predictions)\n",
    "print(\"Root Mean Square Error Value=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|book_id|user_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|    148|    588|     4|  3.334166|\n",
      "|    148|   9731|     3| 3.0050702|\n",
      "|    148|  38475|     4| 3.5628946|\n",
      "|    148|  32055|     3| 3.1493928|\n",
      "|    148|  10610|     4| 3.8776627|\n",
      "|    148|  33065|     3| 3.6576066|\n",
      "|    148|  11569|     2| 3.5303752|\n",
      "|    148|   8510|     3| 3.2779126|\n",
      "|    148|  23576|     3| 2.9999418|\n",
      "|    148|  11239|     2| 2.6207309|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=model.transform(validation_df)\n",
    "predictions.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|user_id|     title|prediction|\n",
      "+-------+----------+----------+\n",
      "|  12466|Lysistrata| 3.7099333|\n",
      "|  12761|Lysistrata|  4.362381|\n",
      "|  37449|Lysistrata|  5.036833|\n",
      "|  38734|Lysistrata| 4.6518354|\n",
      "|  27512|Lysistrata|  3.472881|\n",
      "+-------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.join(books_df,\"book_id\").select(\"user_id\",\"title\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_one_user=predictions.filter(col(\"user_id\")==35982).join(books_df,\"book_id\").select(\"user_id\",\"title\",\"image_url\",\"prediction\")\n",
    "for_one_user.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------+\n",
      "|user_id|               title|           image_url|prediction|\n",
      "+-------+--------------------+--------------------+----------+\n",
      "|  35982|Stranger in a Str...|https://images.gr...| 3.5319219|\n",
      "|  35982|           The Lover|https://images.gr...| 3.9190702|\n",
      "|  35982|The Lord of the R...|https://s.gr-asse...| 4.1712995|\n",
      "+-------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for_one_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger in a Strange Land\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://images.gr-assets.com/books/1156897088m/350.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lover\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://images.gr-assets.com/books/1423329337m/275.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lord of the Rings: Weapons and Warfare\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for book in for_one_user.take(10):\n",
    "    print(book.title)\n",
    "    display(Image(url=book.image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genarates top 5 books recommendations for each user\n",
    "userRecommends=model.recommendForAllUsers(5)\n",
    "#Genarates top 5 user recommendations for each book\n",
    "bookRecommends=model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------+\n",
      "|user_id|book_id                       |\n",
      "+-------+------------------------------+\n",
      "|148    |[7844, 862, 3885, 3628, 6902] |\n",
      "|463    |[4154, 1338, 5202, 3124, 7264]|\n",
      "|471    |[8013, 6457, 7844, 4653, 8233]|\n",
      "|496    |[7844, 6457, 1338, 8013, 9076]|\n",
      "|833    |[3628, 8233, 4706, 862, 7844] |\n",
      "|1088   |[7844, 8233, 6457, 8013, 4653]|\n",
      "|1238   |[1338, 8013, 6457, 5583, 7844]|\n",
      "|1342   |[7844, 8233, 6457, 3885, 4653]|\n",
      "|1580   |[7844, 9076, 3885, 4868, 8187]|\n",
      "|1591   |[9842, 3628, 8109, 6590, 5207]|\n",
      "+-------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommends.select(\"user_id\",\"recommendations.book_id\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- book_id: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommends.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------+\n",
      "|book_id|user_id                            |\n",
      "+-------+-----------------------------------+\n",
      "|1580   |[11196, 48814, 33685, 28480, 48459]|\n",
      "|4900   |[11196, 33685, 48459, 48814, 14798]|\n",
      "|5300   |[44737, 13210, 34667, 26969, 10085]|\n",
      "|6620   |[44737, 34667, 26969, 10085, 13210]|\n",
      "|7240   |[44737, 13210, 48814, 34667, 10085]|\n",
      "|7340   |[48814, 33685, 48459, 10085, 34995]|\n",
      "|7880   |[11196, 28480, 30776, 24883, 48814]|\n",
      "|9900   |[44737, 13210, 34667, 10085, 26969]|\n",
      "|471    |[11196, 33685, 48814, 48459, 28480]|\n",
      "|1591   |[11196, 48814, 33685, 48459, 28480]|\n",
      "+-------+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookRecommends.select(\"book_id\",\"recommendations.user_id\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|user_id|\n",
      "+-------+\n",
      "|  32592|\n",
      "|  19984|\n",
      "|  35982|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Genarate top 10 book recommendations for a specified users\n",
    "users=ratings_df.select(\"user_id\",).distinct().limit(3);\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetRecs=model.recommendForUserSubset(users,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|  32592|[[862, 4.8267784]...|\n",
      "|  35982|[[8233, 4.8680177...|\n",
      "|  19984|[[4868, 6.136679]...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------+\n",
      "|user_id|book_id                                                    |\n",
      "+-------+-----------------------------------------------------------+\n",
      "|32592  |[862, 3628, 1788, 5207, 3395, 6920, 2244, 6902, 6590, 4706]|\n",
      "|35982  |[8233, 9531, 6089, 4706, 3628, 1487, 4778, 2681, 27, 192]  |\n",
      "|19984  |[4868, 9076, 862, 8187, 5207, 7844, 6920, 3885, 7254, 1788]|\n",
      "+-------+-----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.select(\"user_id\",\"recommendations.book_id\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|book_id|\n",
      "+-------+\n",
      "|    148|\n",
      "|    463|\n",
      "|    471|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Genarate top 10 user recommendations for a specified set of books\n",
    "books=ratings_df.select(\"book_id\").distinct().limit(3)\n",
    "books.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------+\n",
      "|book_id|user_id                                                               |\n",
      "+-------+----------------------------------------------------------------------+\n",
      "|471    |[11196, 33685, 48814, 48459, 28480, 52352, 30776, 3498, 14798, 34995] |\n",
      "|463    |[11196, 33685, 48459, 14798, 44737, 48814, 52352, 45652, 28480, 30776]|\n",
      "|148    |[11196, 48814, 33685, 48459, 28480, 30776, 52352, 3498, 34995, 34848] |\n",
      "+-------+----------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookSubSetRecs=model.recommendForItemSubset(books,10)\n",
    "bookSubSetRecs.select(\"book_id\",\"recommendations.user_id\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user prediction and match with to-read list\n",
    "book_ids=[860,1524,2885,2914,5297,7397,8802,9506]\n",
    "user_ids=[4917,4917,4917,4917,4917,4917,4917,4917]\n",
    "new_user_preds=sqlContext.createDataFrame(zip(book_ids,user_ids),schema=[\"book_id\",\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|book_id|user_id|\n",
      "+-------+-------+\n",
      "|    860|   4917|\n",
      "|   1524|   4917|\n",
      "|   2885|   4917|\n",
      "|   2914|   4917|\n",
      "|   5297|   4917|\n",
      "|   7397|   4917|\n",
      "|   8802|   4917|\n",
      "|   9506|   4917|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_user_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|book_id|user_id|prediction|\n",
      "+-------+-------+----------+\n",
      "|   2914|   4917| 3.1179912|\n",
      "|    860|   4917| 3.4302592|\n",
      "|   2885|   4917| 3.2912302|\n",
      "|   7397|   4917| 3.3413641|\n",
      "|   8802|   4917| 3.1044192|\n",
      "|   9506|   4917| 2.7349272|\n",
      "|   1524|   4917| 3.4710765|\n",
      "|   5297|   4917| 3.4524393|\n",
      "+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_predictions=model.transform(new_user_preds)\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
